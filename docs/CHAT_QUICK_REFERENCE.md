# Chat Upload & Multi-Model - Quick Reference

> Schnellreferenz f√ºr die wichtigsten Commands

## üìã Commands √úbersicht

### Chat Management

| Command | Beschreibung | Beispiel |
|---------|--------------|----------|
| `@bot upload-chat text` | Text-Chat hochladen | `@bot upload-chat text`<br>`User: Hallo`<br>`Assistant: Hi!` |
| `@bot upload-chat json` | JSON-Chat hochladen | `@bot upload-chat json`<br>`[{"role":"user","content":"Hi"}]` |
| `@bot ask [frage]` | Frage stellen | `@bot ask Was ist AI?` |
| `@bot ask:[model] [frage]` | Mit spezifischem Modell | `@bot ask:claude-opus Schreibe Artikel` |
| `@bot export-chat` | Chat exportieren | `@bot export-chat` |
| `@bot clear-history` | Historie l√∂schen | `@bot clear-history` |

### Model Management

| Command | Beschreibung | Beispiel |
|---------|--------------|----------|
| `@bot models` | Alle Modelle anzeigen | `@bot models` |
| `@bot switch-model [name]` | Modell wechseln | `@bot switch-model ollama-qwen` |

## ü§ñ Verf√ºgbare Modelle

| Name | API | Kosten | Verf√ºgbarkeit |
|------|-----|--------|---------------|
| `claude` | Anthropic | $0.25/1M | ANTHROPIC_API_KEY |
| `claude-sonnet` | Anthropic | $3/1M | ANTHROPIC_API_KEY |
| `claude-opus` | Anthropic | $15/1M | ANTHROPIC_API_KEY |
| `kimi` | Moonshot | $0.0001/1K | MOONSHOT_API_KEY |
| `ollama-qwen` | Local | FREE | Ollama lokal |
| `ollama-mistral` | Local | FREE | Ollama lokal |

## üìù Chat Formate

### Text Format
```
@bot upload-chat text
User: Erste Nachricht
Assistant: Antwort darauf
User: N√§chste Frage
Assistant: N√§chste Antwort
```

### JSON Format
```
@bot upload-chat json
[
  {"role": "user", "content": "Nachricht 1"},
  {"role": "assistant", "content": "Antwort 1"},
  {"role": "user", "content": "Nachricht 2"}
]
```

### Markdown Format
```
@bot upload-chat markdown
## User
Erste Nachricht

## Assistant
Antwort darauf

## User
N√§chste Frage
```

## üí° Typische Workflows

### Workflow 1: Chat vom Mac √ºbertragen
```
# Schritt 1: Chat hochladen
@bot upload-chat text
User: [Dein Chat vom Mac]
Assistant: [Antworten vom Mac]

# Schritt 2: Weiter chatten
@bot ask Kannst du das zusammenfassen?
```

### Workflow 2: G√ºnstig testen, dann Qualit√§t
```
# Mit Kimi/Ollama starten (g√ºnstig/kostenlos)
@bot switch-model kimi
@bot ask Erste Ideen zu meinem Projekt?

# F√ºr finale Version zu Claude wechseln
@bot switch-model claude-opus
@bot ask Schreibe die finale Version
```

### Workflow 3: Multi-Model Vergleich
```
@bot switch-model kimi
@bot ask [Frage]

@bot switch-model claude-sonnet
@bot ask [Gleiche Frage]

@bot switch-model ollama-qwen
@bot ask [Gleiche Frage]
```

## üéØ Best Practices

### Kosten sparen
1. **95% mit Ollama (lokal)** ‚Üí Kostenlos!
2. **4% mit Kimi** ‚Üí Sehr g√ºnstig
3. **0.9% mit Claude Haiku** ‚Üí G√ºnstig
4. **0.1% mit Claude Opus** ‚Üí Nur f√ºr kritische Tasks

### Modell-Wahl
- **Code/Development** ‚Üí `ollama-qwen` (Qwen 2.5 Coder)
- **Allgemeine Fragen** ‚Üí `kimi` oder `ollama-mistral`
- **Wichtige Tasks** ‚Üí `claude-sonnet`
- **Kritische/Komplexe** ‚Üí `claude-opus`

### Chat Upload
- Nutze `text` f√ºr einfache Chats
- Nutze `json` f√ºr strukturierte Daten
- Nutze `markdown` f√ºr formatierte Chats
- Exportiere wichtige Chats mit `@bot export-chat`

## üö® Troubleshooting

| Problem | L√∂sung |
|---------|--------|
| Model nicht verf√ºgbar | `@bot models` ‚Üí Check API Keys |
| Ollama Error | Ollama muss laufen: `ollama serve` |
| Rate Limits | Zu kostenlosem Ollama wechseln |
| Upload schl√§gt fehl | Format checken (text/json/markdown) |

## üìû Hilfe

```
@bot help          # Alle Commands
@bot models        # Verf√ºgbare Modelle
@bot status        # System Status
```

## üîó Dokumentation

- [Vollst√§ndige Anleitung](./CHAT_UPLOAD_GUIDE.md)
- [GitHub Control System](../GITHUB_CONTROL_SYSTEM.md)
- [Hauptdokumentation](../README.md)

---

**Pro-Tipp:** Nutze Ollama lokal f√ºr 95% der Tasks ‚Üí Spart massiv Kosten! üí∞
