# EXPERIMENT DESIGN
**Date**: 20260211_0341

# Rigorous Experiment Design

## HYPOTHESIS
"H3: How-to threads get more bookmarks than Why-to."

## EVIDENCE REQUIRED
1. Number of total posts in both categories ("How-to" and "Why-to") on a specific forum or platform for the experiment period (e.g., 6 months).
2. Total number of bookmark actions each post receives within these two categories during this time frame.
3. Average number of bookmarks per How-to thread versus Why-to threads.

## FASTEST EXPERIMENT
1. Select one popular online community with a large and active user base, ensuring both "How-to" (tutorials) posts are clearly categorized as such by the platform's guidelines for accurate classification; similarly define 'Why-to' category.
2. Monitor two randomly chosen sample groups of threads: 50% tagged as How-to and another 50% labelled Why-to within a given period over one month, with regular data collection (daily/weekly) to avoid seasonality effects.

## METRIC
- The average number of bookmarks per thread in the 'How-to' category should be at least **X** times higher than that for 'Why-to'. For instance, if How-to threads receive an X% increase compared to Why-to's mean bookmark count (a 2.5x or greater ratio would indicate significantly more engagement), then our metric threshold will reflect this.

## DECISION RULE
- If the average number of bookmarks per thread in "How-to" category exceeds by at least **X** times that for 'Why-to', we can conclude H3 is supported with Y% confidence (where Y corresponds to a statistically significant level, e.g., 80%, derived from our sample size and variance).

---

To ensure precision:

- Randomly select posts within the first month of observation period.
- Monitor both categories until achieving consistent bookmark counts or reaching predefined collection end dates. 

This experiment design aims at capturing real-world interactions with threads across different communities to test H3 effectively while maintaining efficiency in data gathering, processing time and cost-efficiency through online platforms' built-in analytics tools.

---

The success of this experimental setup relies on the platform's accurate categorization capabilities for 'How-to' versus 'Why-to', consistent monitoring practices over a sufficient period (e.g., 1 month), random selection processes to avoid sampling bias or skewed observations. Finally, robust data collection methods through online platforms with built-in analytics tools will ensure real-time observation and analysis of bookmark counts across the two categories.

Note: Adjust X depending on your expectations for statistically significant results based on initial exploratory analyses/data distribution characteristics (e.g., mean/median/bookmark count ratio).

---
STATUS: READY FOR EXECUTION